 
\chapter{Theory}

\section{Audio processing for speech recognition}

An important step in most speech recognition applications is feature extraction: From a raw audio signal we wish to extract information (features) that can be used to effectively process or model the speech to achieve some desired result.
As the exact types of features used vary depending on the model used and the goal of the application, this section will focus on some particularly common features used in speech recognition.
Additionally, some standard methods of processing speech that take into consideration the sequential and dynamic nature of speech will be discussed.

This section serves as a superficial introduction to signal processing for speech recognition.
For a more in-depth description, see a book on signal processing such as \textcite{quatieri2002discrete}, or see \textcite{huang2001spoken} for an introduction to speech recognition in particular.

\subsection{Audio signals}

In the real world speech takes the form of a pressure wave generated as air is pushed through the vocal tract.
The pressure wave as perceived from a single point in space can be described as a continuous signal $x(t)\; (t\in \mathbb{R})$ \todo{notation for domain?} that varies smoothly in time, with $x(t)$ at each time $t$ describing the amplitude of the wave relative to the ambient pressure.
Our perception of the signal depends not on the absolute value of $x(t)$ at any given time instant, but rather on how it varies in time.
As an example, take a simple sine wave $x(t) = \sin(2\pi f t)$; though the signal oscillates continuously in time, a human would perceive the signal as a single constant sound of frequency $f$.

\todo[inline]{don't imply that human hearing has infinite resolution}
However, unlike the human ear, digital computers are unable to handle signals with an infinitely high time resolution, and as a consequence the signal must be somehow discretised before it can be processed further by speech applications.
This is done by taking samples of the signal at fixed time steps given by a sampling frequency $f_s$ (e.g.\ \SI{16000}{\Hz}), specifying the number of samples taken per second.
The resulting sampled signal $x[n]\; (n \in \mathbb{Z})$ is a discrete-time approximation of the original signal $x(t)$.

\subsection{Short-time Fourier transform}

\todo[inline]{include a figure showing the transition from time to frequency domain}
\todo[inline]{maybe mention window functions?}
\todo[inline]{something about the Nyquist frequency}

To mirror how humans percieve audio signals it is useful to transfer the signal to some form that better captures the fluctuations of the signal.
One way is to analyse the \emph{frequency content} of the signal using the Fourier transform.
The Fourier transform approximates the signal using a sum of sine and cosine waves of different frequencies, giving the amplitude of each such wave, which in turn can be interpreted as the energy content of the signal at the corresponding frequency.
In particular, the discrete Fourier transform (DFT), defined as
\[
X(k) = \sum_{n=0}^{N-1} x[n]e^{-j2\pi kn/N}
\]
where $j$ is the imaginary unit and $k \in [0, N-1]$ corresponds to the frequency $f = \frac{k}{N}f_s$, gives the frequency content of a finite discrete-time signal of length $N$ samples.
The energy density, or the energy distribution over frequency, is given by $S(k) = \left|X(k)\right|^2$.
The DFT can be calculated in $O(N \log N)$ asymptotic time using the fast Fourier transform (FFT) algorithm, especially in the case where $N$ is chosen to be a power of 2 \parencite{cooley1965algorithm}.

\todo[inline]{sources for the paragraph below}

The DFT makes certain assumptions regarding the nature of the signal.
In particular, it assumes that the signal is periodic, which is emphatically not true in general for speech signals.
However, a speech signal can be thought to be \emph{approximately periodic} over a very short time period.
This gives rise to the so-called short-time Fourier transform (STFT), where the DFT is calculated repeatedly on short sections of the signal using a sliding window.
A typical window length is \SI{25}{\ms}, and it is generally shifted forward about \SI{10}{\ms} between each DFT calculation.
The result of the STFT is the 2D Fourier transform $X(m,k)$ over time step $m$ and frequency $k$, with corresponding energy density $S(m,k) = \left|X(k,m)\right|^2$.

\subsection{Mel-scale filter banks}

There are several problems with working directly with the output of the STFT. One is that the output is too high-dimensional, as $N$ is often chosen to be in the \numrange{512}{2048} range for the DFT.
Unless very large amounts of data is available, this causes data sparsity issues, which can cause many kinds of models to underperform.
Additionally, we are not really interested in the exact energy at every frequency step, but 
rather the overall shape of the spectrum.

Finally, all frequencies are not created equal, as the human ear does not discriminate between higher frequencies to the same extent as between lower frequencies.
To model this phonemenon, scales in which a change in pitch corresponds roughly linearly to the subjective change in pitch perceived by a human have been empirically developed.
One such scale, ubiquitous in speech technology, is the mel scale, which was developed through experiments where participants were told to produce a tone with half the perceived pitch of a reference tone \parencite{stevens1937scale}.
A frequency $f$ can be converted to the mel scale through the following relation:
\[
  \mathrm{mel}(f) = 1127\log\left(1 + \frac{f}{700}\right)
\]
where $\log$ is the natural logarithm.
As can be seen in \cref{fig:mel-scale}, as $f$ grows larger, the difference $\mathrm{mel}(f+\varepsilon) - \mathrm{mel}(f)$ becomes smaller.

Addressing both the issues of dimensionality and perception, we construct the mel-scale filter bank.
The filter bank is a set of $L$ triangular filters, with the middle points of the filters spaced linearly on the mel scale.
In other words, if $f_1, f_2, \dots, f_L$ are the middle points of the filters specified in \si{\Hz}, $\mathrm{mel}(f_k) - \mathrm{mel}(f_{k-1}) = \mathrm{mel}(f_{k+1}) - \mathrm{mel}(f_k)$, $k \in [2, L-1]$.
The start and end points of the filters are the middle points of the previous and following filters, respectively, with the exception of the first filter whose start point is specified by a lower bound $f_{low}$, and the last filter whose end point is given by a higher bound $f_{high}$.
The height of the peak of each filter can vary; common approaches are to ensure that the filters have either constant height or constant area.
An illustration of a filter bank is given in \cref{fig:filter-bank}.
Each filter is applied to the energy spectrum of the audio signal, giving the filter bank output $E(m,l) = \sum_{k=0}^{N-1}V_l(k)S(m,k)$, where $V_l(k)$ is the $(l+1)$th mel-scale filter.
The resulting $L$ values at each time step $m$ form a rough approximation of the energy spectrum, with the resolution being higher for low frequencies than for high frequencies.
$L$ is commonly chosen to be in the \numrange{20}{40} range, significantly lowering the dimensionality of the data.

\subsection{Mel frequency cepstral coefficients}

In certain applications, it is beneficial if the features generated are relatively decorrelated.
For instance, this is the case when modelling the features using multivariate Gaussian distributions, where if the features are decorrelated the covariance matrix can be approximated using a diagonal matrix, significantly reducing the number of parameters that need to be learnt.

\todo[inline]{talk about what the DCT does}
Unfortunately, the mel-scale filter bank outputs are \emph{not} decorrelated, as neighbouring frequencies tend to take on similar values in the energy spectrum.
However, they can be made roughly decorrelated by taking the discrete cosine transform of the logarithm of the filter bank outputs, given as
\[
C(m,c) = \sum_{l=0}^{L-1} \log(E(m,l)) \cos\left[\frac{2\pi}{L}\left(l+\frac{1}{2}\right)c\right]
\]
for $c \in [0, L - 1]$.
The resulting values are known as the mel-frequency cepstral coefficients (MFCCs).
Usually only the first 13 or so coefficients are used at each time step, i.e.\ the coefficients corresponding to $c \in [0, 12]$, once again reducing the dimensionality of the data.

\subsection{Modelling evolution over time}

Speech is inherently sequential.
This means that our perception of speech is not dependent on particular absolute values of the speech signal at particular points in time, but rather on how the signal evolves over time, and the exact realisation of individual speech sounds is formed through complex interplay with neighbouring sounds.
In addition, many speech sounds change over time by nature; examples include the diphthong /aɪ/ in the word \emph{my} /maɪ/, or the affricate /tʃ/ in \emph{teach} /tiːtʃ/, both acting as single units of speech, despite the onset and offset of the sounds being significantly different acoustically.

Thus, it is a difficult task to recognise a speech sound based only on a single frame of audio.
Instead, the model needs some way of incorporating information about the context of the frame.
This can be done both at the model level and the feature level.
Model-based approaches include hidden Markov models (HMMs), which encode information about how the speech can change in time in the form of probabilities, and recurrent neural networks (RNNs), which can take sequences as input and automatically find temporal patterns.

Feature-based approaches, instead, incorporate temporal information directly into the features.
One simple way is to extend each speech frame to include not only the current frame, but also the neighbouring frames before feeding it to the model.
For instance, if our features consisted of the outputs of a mel-scaled filter bank of size 40 at different time steps $m$ and we wanted to include a context of 2 frames in both directions it time, the frame at each $m$ would be extended to include the frames at $m-2$, $m-1$, $m$, $m+1$ and $m+2$, resulting in a feature vector of size $40\cdot5 = 200$ at each time step.

Another feature-based approach is to include approximations of the temporal derivatives in the feature vector, most commonly the first-order (velocity) and second-order (accerelation) derivatives.
\todo[inline]{include derivation of the delta formulas here}

\subsection{Dynamic time warping}

Speech is also inherently dynamic.
A single speaker if asked to repeat a word two times will not pronounce the word exactly the same both times, and the length of the utterances will also differ slightly.
As a result of this, direct comparison of two utterances in order to measure their similarity becomes difficult.
Dynamic time warping (DTW) attempts to solve this problem by finding the best alignment of the frames of the two utterances and measure the similarity based on this alignment.

Let $d(\mat x, \mat y)$ be some local measure of the distance between the feature vectors $\mat x$ and $\mat y$ (e.g.\ the Euclidean distance) so that $d(\mat x, \mat y)$ is larger the further apart the feature vectors are.
Let $\mat X = \{\mat x_1, \mat x_2, \dots, \mat x_n\}$ and $\mat Y = \{\mat y_1, \mat y_2, \dots, \mat y_m\}$ be sequences of feature vectors, and let $\mat X_{k:l}$ denote the subsequence of $\mat X$ starting at $k$ and ending at $l$. 
We wish to find a global distance measure $D(\mat X, \mat Y)$ as a sum of the local distances between the feature vectors, based on some alignment that minimises this distance.
All elements in both sequences must be used in the final alignment, but elements may be repeated at will to serve as padding.

This can be expressed through the recurrence
\begin{align*}
D(\mat X_{1:k}, \mat Y_{1:l}) = d(\mat x_k, \mat y_l) + \min(&D(\mat X_{1:k-1}, \mat Y_{1:l-1}), \\
& D(\mat X_{1:k-1}, \mat Y_{1:l}), \\
& D(\mat X_{1:k}, \mat Y_{1:l-1}))
\end{align*}
with the base cases
\begin{align*}
  D(\mat X_{1:0}, \mat Y_{1:0}) &= 0 \\
  D(\mat X_{1:0}, \mat Y_{1:k}) = D(\mat X_{1:k}, \mat Y_{1:0}) &= \infty.
\end{align*}
Padding with $\infty$ is required to ensure that the alignment starts with the first element in both sequences.

The way the recurrence is defined enables evaluation of $D(\mat X, \mat Y)$ in $O(nm)$ time using dynamic programming.
By saving backpointers during the calculation, it is also possible to retrieve the actual alignment.

\section{Machine learning}

Machine learning is the practice of automatically finding patterns in data, and use these patterns to make future predictions or perform decision making.
The learning process generally takes the form of setting up an appropriate mathematical or statistical model, and automatically changing the parameters of the model to fit the data.
Machine learning is commonly employed in a variety of fields such as speech recognition, computer vision and natural language processing (NLP).

Using text parsing in NLP as an example, machine learning provides several advantages over the classic approach of hand-engineered rules written by human experts, including:
\todo[inline]{make better arguments}
\begin{itemize}
 \item Grammatical rules are inferred based on actual data, rather than the expert's conception of how the language works.
 \item A computer can quickly go through an amount of data that would be far too vast for a human expert to analyse by hand.
 \item A machine learning model can incorporate statistical information learnt from large amounts of data, enabling it to return multiple possible interpretations along with confidence scores.
\end{itemize}
Similar advantages can be seen in other fields, such as speech recognition where it is simply not feasible to construct hand-written rules that can identify speech sounds from raw audio data.

This section will lightly touch upon machine learning concepts relevant to this thesis; for a proper introduction to the field, see \textcite{murphy2012machine}.

\subsection{Important concepts}
\subsubsection{Supervised and unsupervised learning}

A large number of techniques in machine learning can be broadly considered to be either supervised techniques, which take a set of data along with corresponding labels and try to learn the mapping from the data to the labels, or unsupervised techniques, which try to find ``interesting'' (as defined by the task at hand) patterns in unlabelled data.

As an example, consider the task of speech recognition.
The data set used to train our model consists of speech data along with a set of phonetic transcriptions, so that what is being said at each time instant is known.
Our task is to try to learn this mapping from speech to transcription, taking advantage of all available data.
This is a typical example of supervised learning, as we have a known ``ground truth'' that we are trying to replicate.

On the other hand, consider the case where our speech data is unlabelled, so that we do not know what is being said in a given utterance.
Without the ground truth we do not have a reference we can use to learn the mapping from speech signal to transcription.
Instead, our task is reduced to trying to find patterns in the data, by for example identifying repeating segments in the speech that could possibly correspond to speech sounds, or even whole words.
Note, however, that even if we are able to correctly identify words in the speech, we still do not know the corresponding orthographic transcription.
This is an example of unsupervised learning.

\subsubsection{Regression}

Regression is a supervised task where we are given input data $\mat x \in \mathbb{R}^n$---here real, though discrete input data is also common---and corresponding continuous output data $\mat y \in \mathbb{R}^m$, and our task is to find a function $f:\mathbb{R}^n \to \mathbb{R}^m$ that best preserves the relationship between input and output, and that can be used to predict output values for future input data.

A typical example might be predicting house prices, where the input data consists of information such as floor area, garden area, proximity to public transport, etc., and the output is a scalar indicating the price.

\subsubsection{Classification}

Classification is a special case of regression where the output is a discrete class.
Thus, the problem is finding a function $f:\mathbb{R}^n \to C$ where $C$ is the set of possible classes.
In some cases a data point may belong to more than one class at a time, in which case the mapping function can be defined as $f:\mathbb{R}^n \to \{0,1\}^c$, where $c$ is the number of possible classes, and $f(\mat x)_k$ is $1$ if $\mat x$ belongs to class $k$; this is known as multi-label classification.

A common classification task is image classification, where the objective is to identify the object or objects present in an image.
The input is the value of each pixel in the image, and the output is the class or set of classes corresponding to the object(s) in the image.

\subsubsection{Clustering}

Clustering is an unsupervised task, where the goal is to somehow group the input data into distinct classes, such that data points in one class are more similar to each other than to data points in other classes.
Both the concept of similarity and the interpretation of the different classes depends on the problem at hand.
One example of clustering is the grouping of speech frames generated from an audio signal into distinct phonetic classes, with no prior knowledge of what phonetic classes are available.

\subsection{Gaussian mixture models}

\todo[inline]{is $P(k)$ rigorous notation? also the pdf notation}
When performing clustering, the resulting clusters will strongly depend on our underlying assumptions.
One common assumption is that each data point was generated by one of $K$ multivariate Gaussian distributions, each Gaussian $k$ having mean $\boldsymbol \mu_k$ and covariance matrix $\boldsymbol \Sigma_k$.
The probability of the $k$th Gaussian generating a data point being $P(k \mid \boldsymbol \theta) = \pi_k$, where $\sum_{k=1}^K \pi_k = 1$.
The probability of seeing a data point $\mat x$ is then described by the probability density function
\[
f(\mat x \mid \boldsymbol \theta) = \sum_{k=1}^K P(k \mid \boldsymbol \theta)f(\mat x \mid k, \boldsymbol \theta) = \sum_{k=1}^K \pi_k \mathcal{N}(\mat x;\; \boldsymbol \mu_k,\, \boldsymbol \Sigma_k)
\]
where $\boldsymbol \theta$ is the parameters of the model:
\[
 \boldsymbol \theta = \{\pi_1, \pi_2, \dots, \pi_K, \boldsymbol \mu_1, \boldsymbol \mu_2, \dots, \boldsymbol \mu_K, \boldsymbol \Sigma_1, \boldsymbol \Sigma_2, \dots, \boldsymbol \Sigma_K\}.
\]

This is known as a (finite, as the number of components $K$ is set \emph{a priori}) Gaussian mixture model (GMM).
Clustering using a GMM is performed by initialising the parameters $\boldsymbol \theta$ to some (e.g.\ random) value, and then iteratively updating the parameters using the expectation maximisation (EM) algorithm to maximise the probability of the model having generated the data.
See \textcite{murphy2012machine} for a detailed description of EM for GMMs.

After training, the posterior distribution $P(k \mid \mat x, \boldsymbol \theta)$ can be calculated as
\[
P(k \mid \mat x, \boldsymbol \theta)
= \frac{P(k \mid \boldsymbol \theta)f(\mat x \mid k, \boldsymbol \theta)}{f(\mat x \mid \boldsymbol \theta)}
= \frac{P(k \mid \boldsymbol \theta)f(\mat x \mid k, \boldsymbol \theta)}{\sum_{l=1}^K P(l \mid \boldsymbol \theta)f(\mat x \mid l, \boldsymbol \theta)}
= \frac{\pi_k \mathcal{N}(\mat x;\; \boldsymbol \mu_k, \boldsymbol \Sigma_k)}{\sum_{l=1}^K \pi_l \mathcal{N}(\mat x;\; \boldsymbol \mu_l, \boldsymbol \Sigma_l)},
\]
giving the probability of $\mat x$ belonging to class $k$.

\section{Artificial neural networks}

Artificial neural networks (ANNs) are a family of machine learning models loosely inspired by biological neural networks.
Though different types of ANNs function quite differently from each other, a common theme is that they are composed of a network of units, or neurons, each performing a relatively simple task.
The power of the model comes from combining a large amount of units to form a single, complex model.

This section is mainly concerned with a specific type of neural network, namely the feedforward neural network.
The feedforward neural network is a regression function $f:X \to Y$ that takes an $n$-dimensional input $\mat x \in X$, $X \subseteq \mathbb{R}^n$ and returns an $m$-dimensional output $\mat y \in Y$, $Y \subseteq \mathbb{R}^m$.
Though the model is inherently a regressor, representing both input and output as real values, feedforward neural networks have been successfully applied to e.g.\ classification by interpreting the output $\mat y$ as a probability distribution, defining the probability of $\mat x$ belonging to class $k$ as $P(k \mid \mat x) = y_k$.

For a recent detailed text on ANNs in the context of deep learning, see \textcite{goodfellow2016deep}.

\subsection{Linear models}

Consider the problem of predicting $m$ scalar output variables $y_1, y_2, \dots, y_m$ using a weighted linear combination of $n$ input variables $x_1, x_2, \dots, x_n$: $y_j = \sum_{i=1}^n x_i w_{ij} + b_j$.
In matrix notation we write this as
\[
 \mat y = \mat x \mat W + \mat b
\]
where
\begin{align*}
  \mat x &= \left(\begin{matrix}x_1 & x_2 & \cdots & x_n\end{matrix}\right) \\
  \mat W &= \left(\begin{matrix}
    w_{11} & w_{12} & \cdots & w_{1m} \\
    w_{21} & w_{22} & \cdots & w_{2m} \\
    \vdots & \vdots & \ddots & \vdots \\
    w_{n1} & w_{n2} & \cdots & w_{nm}
  \end{matrix}\right) \\
  \mat b &= \left(\begin{matrix}b_1 & b_2 & \cdots & b_m\end{matrix}\right) \\
  \mat y &= \left(\begin{matrix}y_1 & y_2 & \cdots & y_m\end{matrix}\right).
\end{align*}

$\mat W$ is a weight matrix, defining a different weighted combination of input variables for each $y_j$.
$\mat b$ is a constant term known by a variety of names, including ``bias'', ``threshold'' and ``intercept'', depending on the context.
The interpretation of the bias is not wholly straightforward, but consider the case where each input variable $x_i$ has zero mean; in this case, $b_j$ represents the mean of $y_j$.

This model is known as \emph{linear regression}, or multivariate linear regression in the case of $m > 1$.
The model defines an $n$-dimensional hyperplane for each $y_j$, independently of the other output variables.
$y_j$ increases linearly along a steepest direction given by $\frac{\partial y_j}{\partial \mat x} = (w_{1j}, w_{2j}, \dots, w_{nj})$.

A graphical illustration of the model is provided in \cref{fig:perceptron}.
We consider the model to be composed of two ``layers'': the input layer, $\mat x$, and the output layer, $\mat y$.
Each layer is additionally composed of ``units'', corresponding to the individual scalar variables $x_1,\dots,x_n,y_1,\dots,y_m$.
Every unit in the input layer is connected to every unit in the output layer, each connection representing a single weight.
The output units perform a summation of the weighted input variables before adding a bias value, yielding the final output.

Linear regression can be generalised by inserting a so-called ``activation function'' $g$ before outputting the final value:
\begin{align*}
 \mat y = g(\mat x \mat W + \mat b).
\end{align*}

If $g$ is chosen to be the logistic function $g(\mat z)_j = \sigma(z_j)$, this is known as \emph{logistic regression}.
The logistic function constrains the output to the range of $(0,1)$, allowing $y_j$ to be interpreted as modelling the Bernoulli distribution $P(j=1 \mid \mat x)$.

\subsection{Stacked linear models}
\todo[inline]{universal approximation theorem}

While the generalized model is powerful in its own right, it has fatal drawbacks for certain types of data.
Consider the case of a one-dimensional output $y$ given by $y = g(\mat x \cdot \mat w + b)$, where $\mat w$ is a weight vector.
Let $\mat v$ be a vector orthogonal to $\mat w$, so that $\mat v \cdot \mat w = 0$.
We can now see that $y = g((\mat x + \mat v) \cdot \mat w + b) = g(\mat x \cdot \mat w + \mat v \cdot \mat w + b) = g(\mat x \cdot \mat w + b)$.
In other words, \textbf{linear models cannot discriminate between data points along a direction perpendicular to the weight vector}.
The problem is illustrated in \cref{fig:linear-discriminability}.

However, we can extend our model to enable it to handle more complex data, by stacking several linear models on top of each other.
This is done by inserting a new layer, called a ``hidden'' layer, between the input and output layers.
Let $\mat y^0 = \mat x$ be the input layer, $\mat y^1$ the hidden layer, and $y^2 = y$ the output layer.
We define
\begin{align*}
 y^1_1 &= \varphi(y^0_1) \\
 y^1_2 &= \varphi(y^0_2) \\
 y^2 &= y^1_1 + y^1_2 - 1
\end{align*}
where $\varphi$ is a Gaussian function.
As can be seen in \cref{fig:stacked-gaussian}, this allows us to solve our classification problem.

In general, our stacked model can be defined as
\begin{align*}
 \mat y^0 &= \mat x \\
 \mat y^l &= g^l(\mat y^{l-1} \mat W^l + \mat b^l) \quad l \in [1, N] \\
 \mat y &= \mat y^N
\end{align*}
where $N$ is the number of hidden or output layers, and $g^l$, $\mat W^l$ and $\mat b^l$ are the activation function, weight matrix and bias vector corresponding to layer $l$, respectively.
This is known as a \emph{feedforward artificial neural network}; see \cref{fig:feedforward} for a graphical representation.
By setting
\begin{align*}
g^1(\mat z)_i &= \varphi(z_i) &
\mat W^1 &= \left(\begin{matrix}1 & 0 \\ 0 & 1\end{matrix}\right) &
\mat b^1 &= \mat 0 \\
%
g^2(z) &= z &
\mat W^2 &= \left(\begin{matrix}1 \\ 1\end{matrix}\right) &
b^2 &= -1 \\
\end{align*}
with $N = 2$, we get the previous example.

\subsection{Activation functions}

It is possible to use different activation functions for different layers, or even different units within the same layer.
Typically, however, all hidden layers use the same activation function, with the activation function used for the output layer depending on the task at hand (e.g.\ classification, regression).

\subsubsection{Output layers}

For classification, an activation function that makes it possible to interpret the output as a one or more probability distributions is generally used.
A common choice is the softmax function, which normalises the output to sum to 1:
\[
\mathrm{softmax}(\mat z)_i = \frac{e^{z_i}}{\sum_j e^{z_j}}.
\]
For multi-label classification one can use the logistic function, defined as
\[
\sigma(\mat z)_i = \frac{1}{1 + e^{-z_i}}.
\]

When doing regression, on the other hand, it is common to simply use a linear activation function:
\[
 g(\mat z) = \mat z.
\]

\subsubsection{Hidden layers}
\todo[inline]{sources below}

It can be shown that a stacked model with linear activations in the hidden layers is equivalent to a shallow model with no hidden layers.
Thus, it is vital that the activation function used for the hidden layers is non-linear.
However, it can be advantageous to use a \emph{mostly linear} activation function, not least because both the function itself and its derivative becomes very fast to calculate.

Examples of mostly linear activation functions include the rectified linear unit (ReLU):
\[
\mathrm{ReLU}(\mat z)_i = \max(0, z_i)
\]
and the maxout unit:
\[
\mathrm{maxout}(\mat y^{l-1})_i = \max(\mat y^{l-1} \mat W^l_{\cdot i} + b^l_i, \mat y^{l-1} \mat V^l_{\cdot i} + c^l_i).
\]
Note that the input to maxout is the output of the previous layer rather than a weighted sum; it is a generalisation of the ReLU, keeping multiple sets of weights and biases.

Until recently it was common to use sigmoidal (S-shaped) functions such as the logistic function or $\tanh$ for hidden layers as well, as a way to approximate the spiking behaviour of biological neurons.
However, a major issue with a sigmoidal activation function is that, in addition to being comparatively slow to compute, the derivative of the function quickly falls close to 0 as the function saturates for large and small input values.
This causes training of the network to slow down, especially in networks with many hidden layers where the derivatives of multiple activation functions are multiplied, in a phonemonen known as the ``vanishing gradient'' problem.

\subsection{Training neural networks}
\subsection{Deep neural networks}
